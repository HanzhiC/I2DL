{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNN)\n",
    "====================\n",
    "\n",
    "In this exercise we will work with Recurrent Neural Networks (RNN). A RNN is class of neural networks where the output not only depends on the current input but also on previous inputs along a given input sequence. This allows to exhibit temporal dynamic behaviour and contextual information in a sequence. Common applications for RNN are:\n",
    "\n",
    "- time series analysis\n",
    "- speech recognition\n",
    "- machine translation\n",
    "- image captioning\n",
    "\n",
    "\n",
    "Goal of this exercise\n",
    "========\n",
    "\n",
    "This exercise notebook should help you to experiment how recurrent neural networks are implemented, trained, and used for computer vision problems. Therefore, this notebook is structured as follows:\n",
    "1. Implement your own simple RNN class in Pytorch.\n",
    "2. Explore the backpropagation of the gradients in the RNN and discuss the vanishing gradient problem.\n",
    "3. Implement your own LSTM (Long-Short Term Memory) Network and show that this architecture improves the vanishing gradient problem.\n",
    "4. Build a RNN classifier for the MNIST dataset and train your model.\n",
    "5. Tune the hyperparameters of your model and submit your best model to the server to get bonus points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python:  3.7.3\n",
      "Using torch version:  1.3.1\n",
      "Using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print('Using python: ', platform.python_version())\n",
    "print('Using torch version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "# Machine: 2015 13\" Macbook Pro, i5 dual core"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Recurrent Neural Network\n",
    "\n",
    "The recurrent loops in a RNN allow relevant information to persist over time. A simple RNN architecture is shown here:\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png width=\"150\">\n",
    "\n",
    "A simple RNN takes not only an input X at time step t but also passes a hidden state that is the output of the previous time step into the network. The output of a RNN cell at time step t reads in Eq. 1:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In this task you have to implement a simple one-layer RNN as a class in Pytorch, where you can choose a relu or tanh activation in the cell.You can see the architecture of a simple RNN in the figure below.\n",
    "\n",
    "\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Implement the RNN class\n",
    "from exercise_code.rnn.rnn_nn import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, Pytorch already has implemented a simple RNN in their library and you can call the RNN with <code>nn.RNN</code>. We will use the Pytorch RNN function to check if we have built the correct cell and compare the output of both functions. We also compare the running time of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (torch.zeros (2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import timeit\n",
    "\n",
    "# # choose your network parameters\n",
    "# input_size = 3\n",
    "# hidden_dim = 3\n",
    "# seq_len = 10 \n",
    "\n",
    "# # define the two models\n",
    "# pytorch_rnn=nn.RNN(input_size, hidden_dim)\n",
    "# i2dl_rnn=RNN(input_size, hidden_dim)\n",
    "\n",
    "# # initialise both rnn with same values\n",
    "# for p in pytorch_rnn.parameters():\n",
    "#     nn.init.constant_(p, val=0.3)\n",
    "# for p in i2dl_rnn.parameters():\n",
    "#     nn.init.constant_(p, val=0.3)\n",
    "    \n",
    "# X=torch.randn(seq_len, 1, input_size)\n",
    "# # print (X.shape[0])\n",
    "# # print (X[1,:,:])\n",
    "# output_pytorch, h_pytorch = pytorch_rnn(X)\n",
    "# output_i2dl, h_i2dl = i2dl_rnn(X)\n",
    "\n",
    "# # The difference of outputs should be 0!!\n",
    "# # print (output_pytorch, output_i2dl)\n",
    "# diff = torch.sum((output_pytorch-output_i2dl) ** 2)\n",
    "# print(\"Differnce between pytorch and your RNN implementation: %s\" % diff.item())\n",
    "# if diff.item() < 10 ** -10:\n",
    "#     print(\"Cool, you implemented a correct model.\")\n",
    "# else:\n",
    "#     print(\"Upps! There is something wrong in your model. Try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "# runs=10 ** 4\n",
    "\n",
    "# print(\"Time Pytorch RNN {} runs: {:.3f}s\".format(runs, timeit.timeit(\"pytorch_rnn(X)\", \n",
    "#                                        setup=\"from __main__ import pytorch_rnn, X\", \n",
    "#                                        number=runs))\n",
    "#      )\n",
    "\n",
    "# print(\"Time I2DL RNN {} run: {:.3f}s\".format(runs, timeit.timeit(\"i2dl_rnn(X)\", \n",
    "#                                        setup=\"from __main__ import i2dl_rnn, X\", \n",
    "#                                        number=runs))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on we will use the Pytorch module that is faster and optimised in performance. However, it is always a good exercise to build the functions by yourself and we really advice you to do the exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Gradient\n",
    "\n",
    "As discussed in the lecture, the simple RNN suffers from vanishing gradients in the backpropagation. The hidden state is manipulated in every time step along the sequence and the effect of the past inputs to the final output vanishes with the distance in time. In the next cell we will explore the vanishing effect of previous inputs in the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Define a RNN and explore the gradients on the output h_T wrt. the  #\n",
    "# input at time t and plot your result. What behaviour do you observe?     #\n",
    "# Hints:                                                                   #\n",
    "#   - use one input feature                                                #\n",
    "#   - pytorch allows backward() pass wrt. to any vector                    #\n",
    "#   - backward() can only be applied to scalars and not to output tensors  #\n",
    "#   - choose a good representation of the gradient plot                    #\n",
    "############################################################################\n",
    " \n",
    "    \n",
    "    \n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>It can be seen that the gradient of the output at time t wrt. to a previous input decreases exponentially. Hence, the final output does not change significantly for changes in the previous input and hence the RNN does not have memory.</p> \n",
    "<h3>Question</h3> \n",
    "<p>In order to better understand the vanishing gradient problem, calculate the gradients \n",
    "dh_t/dV, dh_t /dW, and dh_t/dX_0 analytically for t=3 and h_0=0 using Eq. 1. This exercise might seem a little bit tedious but it is really useful. Can you explain the vanishing gradient mathematically based on your findings?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Short Term Memory Network (LSTM)\n",
    "The vanishing gradient problem had been known for some time until Schmidhuber (1997) developed the Long-Short Term Memory Network and showed that this architecture can overcome the problem. <br> \n",
    "A LSTM is a more advanced recurrent network architecture that is able to learn long time dependencies. The architecture of a LSTM is composed of a forget, input, and output gate and the cell can remember values over arbitrary time intervals. Despite various different and exotic LSTM architectures, the standard LSTM cell is shwon in the figure below:\n",
    "\n",
    "\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to a simple RNN the LSTM cell has a hidden vector and an additional cell state vector. __What size does the cell state have?__ <br>\n",
    "The operations inside the LSTM are given as \n",
    "\n",
    "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/2db2cba6a0d878e13932fa27ce6f3fb71ad99cf1  width=\"600\">\n",
    "where \n",
    "f_t: forget gate,  <br>\n",
    "i_t: input gate, <br>\n",
    "o_t: output gate, <br>\n",
    "h_t: hidden state vector, <br>\n",
    "c_t: cell state vector, <br>\n",
    "x_t: input vector, <br>\n",
    "t is time step, \n",
    "<br> \n",
    "<br> \n",
    "and<br> \n",
    "sigma_g: sigmoid activation <br> \n",
    "sigma_c and sigma_h: hyperbolic tangent function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step you should implement your own LSTM with the operations stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Implement the RNN class\n",
    "from exercise_code.rnn.rnn_nn import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # choose your input parameters\n",
    "# input_size = 3\n",
    "# hidden_dim = 3\n",
    "# seq_len = 10 \n",
    "\n",
    "# # define the two models\n",
    "# pytorch_lstm=nn.LSTM(input_size, hidden_dim)\n",
    "# i2dl_lstm=LSTM(input_size, hidden_dim)\n",
    "\n",
    "# # initialise both lstms with same values\n",
    "# for p in pytorch_lstm.parameters():\n",
    "#     nn.init.constant_(p, val=0.3)\n",
    "# for p in i2dl_lstm.parameters():\n",
    "#     nn.init.constant_(p, val=0.3)\n",
    "    \n",
    "# X=torch.randn(seq_len, 1, input_size)\n",
    "\n",
    "# output_pytorch, (h_pytorch, _) = pytorch_lstm(X)\n",
    "# output_i2dl , (h_i2dl, _ )= i2dl_lstm(X)\n",
    "# # print (output_pytorch)\n",
    "# # print (output_i2dl)\n",
    "\n",
    "# # The difference of outputs should be 0!!\n",
    "# diff = torch.sum((output_pytorch-output_i2dl) ** 2)\n",
    "# print(\"Differnce between pytorch and your RNN implementation: %s\" % diff.item())\n",
    "# if diff.item() < 10 ** -10:\n",
    "#     print(\"Cool, you implemented a correct model.\")\n",
    "# else:\n",
    "#     print(\"Upps! There is something wrong in your model. Try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "# runs=10 ** 4\n",
    "\n",
    "# print(\"Time Pytorch LSTM {} runs: {:.3f}s\".format(runs, timeit.timeit(\"pytorch_lstm(X)\", \n",
    "#                                        setup=\"from __main__ import pytorch_lstm, X\", \n",
    "#                                        number=runs))\n",
    "#      )\n",
    "\n",
    "# print(\"Time I2DL LSTM {} runs: {:.3f}s\".format(runs, timeit.timeit(\"i2dl_lstm(X)\", \n",
    "#                                        setup=\"from __main__ import i2dl_lstm, X\", \n",
    "#                                        number=runs))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Gradients \n",
    "Analogously to the RNN, calculate the gradients of the input wrt. to the output of the LSTM and compare it against the RNN gradients. __What do you see?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Define a RNN and LSTM and explore the gradients on the output h_T   #\n",
    "# wrt. the input at time t and plot your result.                           #\n",
    "############################################################################\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST image classification with RNNs\n",
    "\n",
    "In the previous exercises we already have classified images with a Fully Connected and Convolutional Network. In this exercise, we will solve the problem of image classification with a recurrent neural network.  \n",
    "\n",
    "For the experiment we use the MNIST handwritten digits dataset which we already know from the autoencoder exercise. This dataset consists of images of the 10 different digits (10 classes). The images have the resolution 28 x 28. The idea for the RNN classifier is to interpret the image as a sequence of rows. This means that we pass the rows through the RNN and use the final hidden state for classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>\n",
    "    In this semester you have seen three different types of neural networks, namely Multi-Layer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), and now Recurrent Neural Networks (RNNs). We have seen that we can use all three architectures for image classification. However, it turned out that some models are better than others for image classification. Try to think about advantages and disadvantages of the models, regarding # of parameters, transformations of the object in the image (scaling, rotation, translation,...), training time, testing time, over-fitting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "\n",
    "class Unsqueeze(object):\n",
    "    \"\"\"Adds a channel dimension that that our 2 dimensional input (H, W), \n",
    "    fits the 3 dimensional (H, W, C) expectations of pytorch's ToTensor function which\n",
    "    expects a PIL image. This is very inefficient but you most probably will use pytorch's\n",
    "    PIL image loader. Check out the documentation and make it more efficient :)\n",
    "    \"\"\"\n",
    "    def __init__(self, dimension=0):\n",
    "        self.dimension = dimension\n",
    "    def __call__(self, numpy_array):\n",
    "        extended_array = np.expand_dims(numpy_array, self.dimension)\n",
    "        return extended_array\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + 'dimension={}'.format(dimension)\n",
    "\n",
    "    \n",
    "# transformation of data\n",
    "transform = transforms.Compose([\n",
    "    Unsqueeze(dimension=3),     \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "class MnistDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, \n",
    "                 transform=None):\n",
    "        super(MnistDataset, self).__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    \n",
    "# loading the train data\n",
    "with open(\"../datasets/mnist/mnist_train.p\", \"rb\") as f:\n",
    "    mnist_raw = pickle.load(f)\n",
    "\n",
    "X, y = mnist_raw\n",
    "############################################################################\n",
    "# TODO: Set a useful training/ validation split                            #\n",
    "############################################################################    \n",
    "\n",
    "train_split = 0.7\n",
    "\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################\n",
    "\n",
    "\n",
    "train_dset = MnistDataset(X[:int(len(X) * train_split)], y[:int(len(X) * train_split)], transform=transform)\n",
    "val_dset = MnistDataset(X[int(len(X) * train_split):], y[int(len(X) * train_split):], transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples from the dataset. Stolen from other notebooks\n",
    "# We show a few examples of training images from each class.\n",
    "X=train_dset.images\n",
    "y=train_dset.labels\n",
    "\n",
    "\n",
    "classes = list(range(10))\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 5\n",
    "for y_hat, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(train_dset.labels == y_hat)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y_hat + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X[idx])\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier based on a RNN where you sequentially feed the rows in the network and use the final hidden state for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://cdn-images-1.medium.com/max/800/1*Cm_c-I02rBa1rtLZXBhNUw.png width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.rnn.rnn_nn import LSTM_Classifier, RNN_Classifier\n",
    "model_rnn = LSTM_Classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.rnn.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanzzi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 50/19695] TRAIN loss: 1.803\n",
      "[Iteration 100/19695] TRAIN loss: 1.355\n",
      "[Iteration 150/19695] TRAIN loss: 1.031\n",
      "[Iteration 200/19695] TRAIN loss: 0.819\n",
      "[Iteration 250/19695] TRAIN loss: 0.678\n",
      "[Iteration 300/19695] TRAIN loss: 0.533\n",
      "[Iteration 350/19695] TRAIN loss: 0.488\n",
      "[Iteration 400/19695] TRAIN loss: 0.462\n",
      "[Iteration 450/19695] TRAIN loss: 0.376\n",
      "[Iteration 500/19695] TRAIN loss: 0.349\n",
      "[Iteration 550/19695] TRAIN loss: 0.324\n",
      "[Iteration 600/19695] TRAIN loss: 0.276\n",
      "[Iteration 650/19695] TRAIN loss: 0.266\n",
      "[Iteration 700/19695] TRAIN loss: 0.278\n",
      "[Iteration 750/19695] TRAIN loss: 0.249\n",
      "[Iteration 800/19695] TRAIN loss: 0.234\n",
      "[Iteration 850/19695] TRAIN loss: 0.219\n",
      "[Iteration 900/19695] TRAIN loss: 0.190\n",
      "[Iteration 950/19695] TRAIN loss: 0.217\n",
      "[Iteration 1000/19695] TRAIN loss: 0.232\n",
      "[Iteration 1050/19695] TRAIN loss: 0.181\n",
      "[Iteration 1100/19695] TRAIN loss: 0.175\n",
      "[Iteration 1150/19695] TRAIN loss: 0.173\n",
      "[Iteration 1200/19695] TRAIN loss: 0.173\n",
      "[Iteration 1250/19695] TRAIN loss: 0.158\n",
      "[Iteration 1300/19695] TRAIN loss: 0.150\n",
      "[Epoch 1/15] TRAIN acc/loss: 0.938/0.150\n",
      "[Epoch 1/15] VAL   acc/loss: 0.887/0.362\n",
      "[Iteration 1363/19695] TRAIN loss: 0.196\n",
      "[Iteration 1413/19695] TRAIN loss: 0.148\n",
      "[Iteration 1463/19695] TRAIN loss: 0.171\n",
      "[Iteration 1513/19695] TRAIN loss: 0.115\n",
      "[Iteration 1563/19695] TRAIN loss: 0.138\n",
      "[Iteration 1613/19695] TRAIN loss: 0.145\n",
      "[Iteration 1663/19695] TRAIN loss: 0.156\n",
      "[Iteration 1713/19695] TRAIN loss: 0.146\n",
      "[Iteration 1763/19695] TRAIN loss: 0.115\n",
      "[Iteration 1813/19695] TRAIN loss: 0.120\n",
      "[Iteration 1863/19695] TRAIN loss: 0.118\n",
      "[Iteration 1913/19695] TRAIN loss: 0.135\n",
      "[Iteration 1963/19695] TRAIN loss: 0.115\n",
      "[Iteration 2013/19695] TRAIN loss: 0.128\n",
      "[Iteration 2063/19695] TRAIN loss: 0.135\n",
      "[Iteration 2113/19695] TRAIN loss: 0.160\n",
      "[Iteration 2163/19695] TRAIN loss: 0.090\n",
      "[Iteration 2213/19695] TRAIN loss: 0.156\n",
      "[Iteration 2263/19695] TRAIN loss: 0.101\n",
      "[Iteration 2313/19695] TRAIN loss: 0.112\n",
      "[Iteration 2363/19695] TRAIN loss: 0.115\n",
      "[Iteration 2413/19695] TRAIN loss: 0.113\n",
      "[Iteration 2463/19695] TRAIN loss: 0.106\n",
      "[Iteration 2513/19695] TRAIN loss: 0.088\n",
      "[Iteration 2563/19695] TRAIN loss: 0.131\n",
      "[Iteration 2613/19695] TRAIN loss: 0.114\n",
      "[Epoch 2/15] TRAIN acc/loss: 0.938/0.114\n",
      "[Epoch 2/15] VAL   acc/loss: 0.973/0.088\n",
      "[Iteration 2676/19695] TRAIN loss: 0.105\n",
      "[Iteration 2726/19695] TRAIN loss: 0.094\n",
      "[Iteration 2776/19695] TRAIN loss: 0.083\n",
      "[Iteration 2826/19695] TRAIN loss: 0.093\n",
      "[Iteration 2876/19695] TRAIN loss: 0.096\n",
      "[Iteration 2926/19695] TRAIN loss: 0.098\n",
      "[Iteration 2976/19695] TRAIN loss: 0.115\n",
      "[Iteration 3026/19695] TRAIN loss: 0.096\n",
      "[Iteration 3076/19695] TRAIN loss: 0.121\n",
      "[Iteration 3126/19695] TRAIN loss: 0.097\n",
      "[Iteration 3176/19695] TRAIN loss: 0.081\n",
      "[Iteration 3226/19695] TRAIN loss: 0.109\n",
      "[Iteration 3276/19695] TRAIN loss: 0.072\n",
      "[Iteration 3326/19695] TRAIN loss: 0.075\n",
      "[Iteration 3376/19695] TRAIN loss: 0.087\n",
      "[Iteration 3426/19695] TRAIN loss: 0.069\n",
      "[Iteration 3476/19695] TRAIN loss: 0.093\n",
      "[Iteration 3526/19695] TRAIN loss: 0.098\n",
      "[Iteration 3576/19695] TRAIN loss: 0.117\n",
      "[Iteration 3626/19695] TRAIN loss: 0.113\n",
      "[Iteration 3676/19695] TRAIN loss: 0.071\n",
      "[Iteration 3726/19695] TRAIN loss: 0.087\n",
      "[Iteration 3776/19695] TRAIN loss: 0.053\n",
      "[Iteration 3826/19695] TRAIN loss: 0.069\n",
      "[Iteration 3876/19695] TRAIN loss: 0.092\n",
      "[Iteration 3926/19695] TRAIN loss: 0.088\n",
      "[Epoch 3/15] TRAIN acc/loss: 0.938/0.088\n",
      "[Epoch 3/15] VAL   acc/loss: 0.975/0.080\n",
      "[Iteration 3989/19695] TRAIN loss: 0.071\n",
      "[Iteration 4039/19695] TRAIN loss: 0.074\n",
      "[Iteration 4089/19695] TRAIN loss: 0.066\n",
      "[Iteration 4139/19695] TRAIN loss: 0.051\n",
      "[Iteration 4189/19695] TRAIN loss: 0.081\n",
      "[Iteration 4239/19695] TRAIN loss: 0.073\n",
      "[Iteration 4289/19695] TRAIN loss: 0.043\n",
      "[Iteration 4339/19695] TRAIN loss: 0.074\n",
      "[Iteration 4389/19695] TRAIN loss: 0.086\n",
      "[Iteration 4439/19695] TRAIN loss: 0.069\n",
      "[Iteration 4489/19695] TRAIN loss: 0.045\n",
      "[Iteration 4539/19695] TRAIN loss: 0.061\n",
      "[Iteration 4589/19695] TRAIN loss: 0.076\n",
      "[Iteration 4639/19695] TRAIN loss: 0.071\n",
      "[Iteration 4689/19695] TRAIN loss: 0.081\n",
      "[Iteration 4739/19695] TRAIN loss: 0.082\n",
      "[Iteration 4789/19695] TRAIN loss: 0.066\n",
      "[Iteration 4839/19695] TRAIN loss: 0.057\n",
      "[Iteration 4889/19695] TRAIN loss: 0.074\n",
      "[Iteration 4939/19695] TRAIN loss: 0.078\n",
      "[Iteration 4989/19695] TRAIN loss: 0.064\n",
      "[Iteration 5039/19695] TRAIN loss: 0.090\n",
      "[Iteration 5089/19695] TRAIN loss: 0.061\n",
      "[Iteration 5139/19695] TRAIN loss: 0.073\n",
      "[Iteration 5189/19695] TRAIN loss: 0.072\n",
      "[Iteration 5239/19695] TRAIN loss: 0.060\n",
      "[Epoch 4/15] TRAIN acc/loss: 1.000/0.060\n",
      "[Epoch 4/15] VAL   acc/loss: 0.981/0.062\n",
      "[Iteration 5302/19695] TRAIN loss: 0.085\n",
      "[Iteration 5352/19695] TRAIN loss: 0.073\n",
      "[Iteration 5402/19695] TRAIN loss: 0.059\n",
      "[Iteration 5452/19695] TRAIN loss: 0.051\n",
      "[Iteration 5502/19695] TRAIN loss: 0.063\n",
      "[Iteration 5552/19695] TRAIN loss: 0.067\n",
      "[Iteration 5602/19695] TRAIN loss: 0.048\n",
      "[Iteration 5652/19695] TRAIN loss: 0.042\n",
      "[Iteration 5702/19695] TRAIN loss: 0.067\n",
      "[Iteration 5752/19695] TRAIN loss: 0.050\n",
      "[Iteration 5802/19695] TRAIN loss: 0.085\n",
      "[Iteration 5852/19695] TRAIN loss: 0.062\n",
      "[Iteration 5902/19695] TRAIN loss: 0.062\n",
      "[Iteration 5952/19695] TRAIN loss: 0.066\n",
      "[Iteration 6002/19695] TRAIN loss: 0.043\n",
      "[Iteration 6052/19695] TRAIN loss: 0.056\n",
      "[Iteration 6102/19695] TRAIN loss: 0.070\n",
      "[Iteration 6152/19695] TRAIN loss: 0.062\n",
      "[Iteration 6202/19695] TRAIN loss: 0.042\n",
      "[Iteration 6252/19695] TRAIN loss: 0.070\n",
      "[Iteration 6302/19695] TRAIN loss: 0.068\n",
      "[Iteration 6352/19695] TRAIN loss: 0.059\n",
      "[Iteration 6402/19695] TRAIN loss: 0.074\n",
      "[Iteration 6452/19695] TRAIN loss: 0.059\n",
      "[Iteration 6502/19695] TRAIN loss: 0.055\n",
      "[Iteration 6552/19695] TRAIN loss: 0.054\n",
      "[Epoch 5/15] TRAIN acc/loss: 1.000/0.054\n",
      "[Epoch 5/15] VAL   acc/loss: 0.979/0.071\n",
      "[Iteration 6615/19695] TRAIN loss: 0.051\n",
      "[Iteration 6665/19695] TRAIN loss: 0.047\n",
      "[Iteration 6715/19695] TRAIN loss: 0.040\n",
      "[Iteration 6765/19695] TRAIN loss: 0.034\n",
      "[Iteration 6815/19695] TRAIN loss: 0.073\n",
      "[Iteration 6865/19695] TRAIN loss: 0.047\n",
      "[Iteration 6915/19695] TRAIN loss: 0.050\n",
      "[Iteration 6965/19695] TRAIN loss: 0.044\n",
      "[Iteration 7015/19695] TRAIN loss: 0.034\n",
      "[Iteration 7065/19695] TRAIN loss: 0.053\n",
      "[Iteration 7115/19695] TRAIN loss: 0.038\n",
      "[Iteration 7165/19695] TRAIN loss: 0.037\n",
      "[Iteration 7215/19695] TRAIN loss: 0.046\n",
      "[Iteration 7265/19695] TRAIN loss: 0.065\n",
      "[Iteration 7315/19695] TRAIN loss: 0.044\n",
      "[Iteration 7365/19695] TRAIN loss: 0.037\n",
      "[Iteration 7415/19695] TRAIN loss: 0.080\n",
      "[Iteration 7465/19695] TRAIN loss: 0.066\n",
      "[Iteration 7515/19695] TRAIN loss: 0.054\n",
      "[Iteration 7565/19695] TRAIN loss: 0.044\n",
      "[Iteration 7615/19695] TRAIN loss: 0.066\n",
      "[Iteration 7665/19695] TRAIN loss: 0.082\n",
      "[Iteration 7715/19695] TRAIN loss: 0.066\n",
      "[Iteration 7765/19695] TRAIN loss: 0.055\n",
      "[Iteration 7815/19695] TRAIN loss: 0.030\n",
      "[Iteration 7865/19695] TRAIN loss: 0.030\n",
      "[Epoch 6/15] TRAIN acc/loss: 1.000/0.030\n",
      "[Epoch 6/15] VAL   acc/loss: 0.986/0.046\n",
      "[Iteration 7928/19695] TRAIN loss: 0.049\n",
      "[Iteration 7978/19695] TRAIN loss: 0.039\n",
      "[Iteration 8028/19695] TRAIN loss: 0.045\n",
      "[Iteration 8078/19695] TRAIN loss: 0.040\n",
      "[Iteration 8128/19695] TRAIN loss: 0.019\n",
      "[Iteration 8178/19695] TRAIN loss: 0.024\n",
      "[Iteration 8228/19695] TRAIN loss: 0.047\n",
      "[Iteration 8278/19695] TRAIN loss: 0.029\n",
      "[Iteration 8328/19695] TRAIN loss: 0.043\n",
      "[Iteration 8378/19695] TRAIN loss: 0.049\n",
      "[Iteration 8428/19695] TRAIN loss: 0.039\n",
      "[Iteration 8478/19695] TRAIN loss: 0.055\n",
      "[Iteration 8528/19695] TRAIN loss: 0.050\n",
      "[Iteration 8578/19695] TRAIN loss: 0.044\n",
      "[Iteration 8628/19695] TRAIN loss: 0.035\n",
      "[Iteration 8678/19695] TRAIN loss: 0.067\n",
      "[Iteration 8728/19695] TRAIN loss: 0.061\n",
      "[Iteration 8778/19695] TRAIN loss: 0.039\n",
      "[Iteration 8828/19695] TRAIN loss: 0.046\n",
      "[Iteration 8878/19695] TRAIN loss: 0.036\n",
      "[Iteration 8928/19695] TRAIN loss: 0.044\n",
      "[Iteration 8978/19695] TRAIN loss: 0.035\n",
      "[Iteration 9028/19695] TRAIN loss: 0.059\n",
      "[Iteration 9078/19695] TRAIN loss: 0.028\n",
      "[Iteration 9128/19695] TRAIN loss: 0.043\n",
      "[Iteration 9178/19695] TRAIN loss: 0.043\n",
      "[Epoch 7/15] TRAIN acc/loss: 1.000/0.043\n",
      "[Epoch 7/15] VAL   acc/loss: 0.982/0.063\n",
      "[Iteration 9241/19695] TRAIN loss: 0.034\n",
      "[Iteration 9291/19695] TRAIN loss: 0.036\n",
      "[Iteration 9341/19695] TRAIN loss: 0.030\n",
      "[Iteration 9391/19695] TRAIN loss: 0.038\n",
      "[Iteration 9441/19695] TRAIN loss: 0.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9491/19695] TRAIN loss: 0.031\n",
      "[Iteration 9541/19695] TRAIN loss: 0.035\n",
      "[Iteration 9591/19695] TRAIN loss: 0.044\n",
      "[Iteration 9641/19695] TRAIN loss: 0.043\n",
      "[Iteration 9691/19695] TRAIN loss: 0.039\n",
      "[Iteration 9741/19695] TRAIN loss: 0.054\n",
      "[Iteration 9791/19695] TRAIN loss: 0.036\n",
      "[Iteration 9841/19695] TRAIN loss: 0.032\n",
      "[Iteration 9891/19695] TRAIN loss: 0.032\n",
      "[Iteration 9941/19695] TRAIN loss: 0.037\n",
      "[Iteration 9991/19695] TRAIN loss: 0.035\n",
      "[Iteration 10041/19695] TRAIN loss: 0.029\n",
      "[Iteration 10091/19695] TRAIN loss: 0.041\n",
      "[Iteration 10141/19695] TRAIN loss: 0.051\n",
      "[Iteration 10191/19695] TRAIN loss: 0.037\n",
      "[Iteration 10241/19695] TRAIN loss: 0.040\n",
      "[Iteration 10291/19695] TRAIN loss: 0.074\n",
      "[Iteration 10341/19695] TRAIN loss: 0.063\n",
      "[Iteration 10391/19695] TRAIN loss: 0.041\n",
      "[Iteration 10441/19695] TRAIN loss: 0.043\n",
      "[Iteration 10491/19695] TRAIN loss: 0.030\n",
      "[Epoch 8/15] TRAIN acc/loss: 1.000/0.030\n",
      "[Epoch 8/15] VAL   acc/loss: 0.985/0.050\n",
      "[Iteration 10554/19695] TRAIN loss: 0.034\n",
      "[Iteration 10604/19695] TRAIN loss: 0.051\n",
      "[Iteration 10654/19695] TRAIN loss: 0.040\n",
      "[Iteration 10704/19695] TRAIN loss: 0.040\n",
      "[Iteration 10754/19695] TRAIN loss: 0.029\n",
      "[Iteration 10804/19695] TRAIN loss: 0.030\n",
      "[Iteration 10854/19695] TRAIN loss: 0.053\n",
      "[Iteration 10904/19695] TRAIN loss: 0.044\n",
      "[Iteration 10954/19695] TRAIN loss: 0.036\n",
      "[Iteration 11004/19695] TRAIN loss: 0.037\n",
      "[Iteration 11054/19695] TRAIN loss: 0.039\n",
      "[Iteration 11104/19695] TRAIN loss: 0.032\n",
      "[Iteration 11154/19695] TRAIN loss: 0.022\n",
      "[Iteration 11204/19695] TRAIN loss: 0.033\n",
      "[Iteration 11254/19695] TRAIN loss: 0.033\n",
      "[Iteration 11304/19695] TRAIN loss: 0.028\n",
      "[Iteration 11354/19695] TRAIN loss: 0.030\n",
      "[Iteration 11404/19695] TRAIN loss: 0.026\n",
      "[Iteration 11454/19695] TRAIN loss: 0.027\n",
      "[Iteration 11504/19695] TRAIN loss: 0.039\n",
      "[Iteration 11554/19695] TRAIN loss: 0.023\n",
      "[Iteration 11604/19695] TRAIN loss: 0.052\n",
      "[Iteration 11654/19695] TRAIN loss: 0.057\n",
      "[Iteration 11704/19695] TRAIN loss: 0.035\n",
      "[Iteration 11754/19695] TRAIN loss: 0.037\n",
      "[Iteration 11804/19695] TRAIN loss: 0.052\n",
      "[Epoch 9/15] TRAIN acc/loss: 1.000/0.052\n",
      "[Epoch 9/15] VAL   acc/loss: 0.986/0.050\n",
      "[Iteration 11867/19695] TRAIN loss: 0.035\n",
      "[Iteration 11917/19695] TRAIN loss: 0.015\n",
      "[Iteration 11967/19695] TRAIN loss: 0.043\n",
      "[Iteration 12017/19695] TRAIN loss: 0.025\n",
      "[Iteration 12067/19695] TRAIN loss: 0.021\n",
      "[Iteration 12117/19695] TRAIN loss: 0.027\n",
      "[Iteration 12167/19695] TRAIN loss: 0.034\n",
      "[Iteration 12217/19695] TRAIN loss: 0.025\n",
      "[Iteration 12267/19695] TRAIN loss: 0.023\n",
      "[Iteration 12317/19695] TRAIN loss: 0.036\n",
      "[Iteration 12367/19695] TRAIN loss: 0.042\n",
      "[Iteration 12417/19695] TRAIN loss: 0.023\n",
      "[Iteration 12467/19695] TRAIN loss: 0.034\n",
      "[Iteration 12517/19695] TRAIN loss: 0.026\n",
      "[Iteration 12567/19695] TRAIN loss: 0.049\n",
      "[Iteration 12617/19695] TRAIN loss: 0.032\n",
      "[Iteration 12667/19695] TRAIN loss: 0.026\n",
      "[Iteration 12717/19695] TRAIN loss: 0.029\n",
      "[Iteration 12767/19695] TRAIN loss: 0.019\n",
      "[Iteration 12817/19695] TRAIN loss: 0.015\n",
      "[Iteration 12867/19695] TRAIN loss: 0.026\n",
      "[Iteration 12917/19695] TRAIN loss: 0.044\n",
      "[Iteration 12967/19695] TRAIN loss: 0.035\n",
      "[Iteration 13017/19695] TRAIN loss: 0.029\n",
      "[Iteration 13067/19695] TRAIN loss: 0.036\n",
      "[Iteration 13117/19695] TRAIN loss: 0.034\n",
      "[Epoch 10/15] TRAIN acc/loss: 0.938/0.034\n",
      "[Epoch 10/15] VAL   acc/loss: 0.988/0.045\n",
      "[Iteration 13180/19695] TRAIN loss: 0.025\n",
      "[Iteration 13230/19695] TRAIN loss: 0.036\n",
      "[Iteration 13280/19695] TRAIN loss: 0.035\n",
      "[Iteration 13330/19695] TRAIN loss: 0.024\n",
      "[Iteration 13380/19695] TRAIN loss: 0.014\n",
      "[Iteration 13430/19695] TRAIN loss: 0.033\n",
      "[Iteration 13480/19695] TRAIN loss: 0.051\n",
      "[Iteration 13530/19695] TRAIN loss: 0.029\n",
      "[Iteration 13580/19695] TRAIN loss: 0.021\n",
      "[Iteration 13630/19695] TRAIN loss: 0.025\n",
      "[Iteration 13680/19695] TRAIN loss: 0.026\n",
      "[Iteration 13730/19695] TRAIN loss: 0.027\n",
      "[Iteration 13780/19695] TRAIN loss: 0.025\n",
      "[Iteration 13830/19695] TRAIN loss: 0.029\n",
      "[Iteration 13880/19695] TRAIN loss: 0.038\n",
      "[Iteration 13930/19695] TRAIN loss: 0.040\n",
      "[Iteration 13980/19695] TRAIN loss: 0.038\n",
      "[Iteration 14030/19695] TRAIN loss: 0.030\n",
      "[Iteration 14080/19695] TRAIN loss: 0.032\n",
      "[Iteration 14130/19695] TRAIN loss: 0.045\n",
      "[Iteration 14180/19695] TRAIN loss: 0.043\n",
      "[Iteration 14230/19695] TRAIN loss: 0.020\n",
      "[Iteration 14280/19695] TRAIN loss: 0.039\n",
      "[Iteration 14330/19695] TRAIN loss: 0.031\n",
      "[Iteration 14380/19695] TRAIN loss: 0.021\n",
      "[Iteration 14430/19695] TRAIN loss: 0.026\n",
      "[Epoch 11/15] TRAIN acc/loss: 0.938/0.026\n",
      "[Epoch 11/15] VAL   acc/loss: 0.986/0.050\n",
      "[Iteration 14493/19695] TRAIN loss: 0.043\n",
      "[Iteration 14543/19695] TRAIN loss: 0.017\n",
      "[Iteration 14593/19695] TRAIN loss: 0.033\n",
      "[Iteration 14643/19695] TRAIN loss: 0.021\n",
      "[Iteration 14693/19695] TRAIN loss: 0.022\n",
      "[Iteration 14743/19695] TRAIN loss: 0.017\n",
      "[Iteration 14793/19695] TRAIN loss: 0.028\n",
      "[Iteration 14843/19695] TRAIN loss: 0.035\n",
      "[Iteration 14893/19695] TRAIN loss: 0.039\n",
      "[Iteration 14943/19695] TRAIN loss: 0.014\n",
      "[Iteration 14993/19695] TRAIN loss: 0.007\n",
      "[Iteration 15043/19695] TRAIN loss: 0.039\n",
      "[Iteration 15093/19695] TRAIN loss: 0.032\n",
      "[Iteration 15143/19695] TRAIN loss: 0.035\n",
      "[Iteration 15193/19695] TRAIN loss: 0.027\n",
      "[Iteration 15243/19695] TRAIN loss: 0.031\n",
      "[Iteration 15293/19695] TRAIN loss: 0.031\n",
      "[Iteration 15343/19695] TRAIN loss: 0.023\n",
      "[Iteration 15393/19695] TRAIN loss: 0.030\n",
      "[Iteration 15443/19695] TRAIN loss: 0.039\n",
      "[Iteration 15493/19695] TRAIN loss: 0.029\n",
      "[Iteration 15543/19695] TRAIN loss: 0.022\n",
      "[Iteration 15593/19695] TRAIN loss: 0.020\n",
      "[Iteration 15643/19695] TRAIN loss: 0.027\n",
      "[Iteration 15693/19695] TRAIN loss: 0.016\n",
      "[Iteration 15743/19695] TRAIN loss: 0.019\n",
      "[Epoch 12/15] TRAIN acc/loss: 1.000/0.019\n",
      "[Epoch 12/15] VAL   acc/loss: 0.984/0.060\n",
      "[Iteration 15806/19695] TRAIN loss: 0.031\n",
      "[Iteration 15856/19695] TRAIN loss: 0.016\n",
      "[Iteration 15906/19695] TRAIN loss: 0.022\n",
      "[Iteration 15956/19695] TRAIN loss: 0.019\n",
      "[Iteration 16006/19695] TRAIN loss: 0.040\n",
      "[Iteration 16056/19695] TRAIN loss: 0.035\n",
      "[Iteration 16106/19695] TRAIN loss: 0.019\n",
      "[Iteration 16156/19695] TRAIN loss: 0.018\n",
      "[Iteration 16206/19695] TRAIN loss: 0.037\n",
      "[Iteration 16256/19695] TRAIN loss: 0.012\n",
      "[Iteration 16306/19695] TRAIN loss: 0.011\n",
      "[Iteration 16356/19695] TRAIN loss: 0.019\n",
      "[Iteration 16406/19695] TRAIN loss: 0.017\n",
      "[Iteration 16456/19695] TRAIN loss: 0.030\n",
      "[Iteration 16506/19695] TRAIN loss: 0.036\n",
      "[Iteration 16556/19695] TRAIN loss: 0.021\n",
      "[Iteration 16606/19695] TRAIN loss: 0.015\n",
      "[Iteration 16656/19695] TRAIN loss: 0.027\n",
      "[Iteration 16706/19695] TRAIN loss: 0.045\n",
      "[Iteration 16756/19695] TRAIN loss: 0.024\n",
      "[Iteration 16806/19695] TRAIN loss: 0.016\n",
      "[Iteration 16856/19695] TRAIN loss: 0.029\n",
      "[Iteration 16906/19695] TRAIN loss: 0.045\n",
      "[Iteration 16956/19695] TRAIN loss: 0.031\n",
      "[Iteration 17006/19695] TRAIN loss: 0.048\n",
      "[Iteration 17056/19695] TRAIN loss: 0.029\n",
      "[Epoch 13/15] TRAIN acc/loss: 1.000/0.029\n",
      "[Epoch 13/15] VAL   acc/loss: 0.985/0.056\n",
      "[Iteration 17119/19695] TRAIN loss: 0.024\n",
      "[Iteration 17169/19695] TRAIN loss: 0.024\n",
      "[Iteration 17219/19695] TRAIN loss: 0.012\n",
      "[Iteration 17269/19695] TRAIN loss: 0.033\n",
      "[Iteration 17319/19695] TRAIN loss: 0.024\n",
      "[Iteration 17369/19695] TRAIN loss: 0.018\n",
      "[Iteration 17419/19695] TRAIN loss: 0.012\n",
      "[Iteration 17469/19695] TRAIN loss: 0.021\n",
      "[Iteration 17519/19695] TRAIN loss: 0.035\n",
      "[Iteration 17569/19695] TRAIN loss: 0.021\n",
      "[Iteration 17619/19695] TRAIN loss: 0.010\n",
      "[Iteration 17669/19695] TRAIN loss: 0.024\n",
      "[Iteration 17719/19695] TRAIN loss: 0.028\n",
      "[Iteration 17769/19695] TRAIN loss: 0.022\n",
      "[Iteration 17819/19695] TRAIN loss: 0.020\n",
      "[Iteration 17869/19695] TRAIN loss: 0.023\n",
      "[Iteration 17919/19695] TRAIN loss: 0.022\n",
      "[Iteration 17969/19695] TRAIN loss: 0.014\n",
      "[Iteration 18019/19695] TRAIN loss: 0.040\n",
      "[Iteration 18069/19695] TRAIN loss: 0.028\n",
      "[Iteration 18119/19695] TRAIN loss: 0.024\n",
      "[Iteration 18169/19695] TRAIN loss: 0.027\n",
      "[Iteration 18219/19695] TRAIN loss: 0.034\n",
      "[Iteration 18269/19695] TRAIN loss: 0.028\n",
      "[Iteration 18319/19695] TRAIN loss: 0.029\n",
      "[Iteration 18369/19695] TRAIN loss: 0.026\n",
      "[Epoch 14/15] TRAIN acc/loss: 1.000/0.026\n",
      "[Epoch 14/15] VAL   acc/loss: 0.987/0.046\n",
      "[Iteration 18432/19695] TRAIN loss: 0.029\n",
      "[Iteration 18482/19695] TRAIN loss: 0.019\n",
      "[Iteration 18532/19695] TRAIN loss: 0.013\n",
      "[Iteration 18582/19695] TRAIN loss: 0.017\n",
      "[Iteration 18632/19695] TRAIN loss: 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 18682/19695] TRAIN loss: 0.017\n",
      "[Iteration 18732/19695] TRAIN loss: 0.015\n",
      "[Iteration 18782/19695] TRAIN loss: 0.017\n",
      "[Iteration 18832/19695] TRAIN loss: 0.024\n",
      "[Iteration 18882/19695] TRAIN loss: 0.010\n",
      "[Iteration 18932/19695] TRAIN loss: 0.014\n",
      "[Iteration 18982/19695] TRAIN loss: 0.017\n",
      "[Iteration 19032/19695] TRAIN loss: 0.012\n",
      "[Iteration 19082/19695] TRAIN loss: 0.012\n",
      "[Iteration 19132/19695] TRAIN loss: 0.039\n",
      "[Iteration 19182/19695] TRAIN loss: 0.017\n",
      "[Iteration 19232/19695] TRAIN loss: 0.021\n",
      "[Iteration 19282/19695] TRAIN loss: 0.018\n",
      "[Iteration 19332/19695] TRAIN loss: 0.014\n",
      "[Iteration 19382/19695] TRAIN loss: 0.013\n",
      "[Iteration 19432/19695] TRAIN loss: 0.010\n",
      "[Iteration 19482/19695] TRAIN loss: 0.034\n",
      "[Iteration 19532/19695] TRAIN loss: 0.020\n",
      "[Iteration 19582/19695] TRAIN loss: 0.038\n",
      "[Iteration 19632/19695] TRAIN loss: 0.023\n",
      "[Iteration 19682/19695] TRAIN loss: 0.018\n",
      "[Epoch 15/15] TRAIN acc/loss: 1.000/0.018\n",
      "[Epoch 15/15] VAL   acc/loss: 0.983/0.066\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_dset,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                dataset=val_dset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "solver = Solver(optim_args={\"lr\": 1e-3})\n",
    "\n",
    "# train rnn model\n",
    "solver.train(model_rnn, train_loader, val_loader, log_nth=50, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your RNN classifier and try to tune the hyperparameters. With your simple RNN classifier you should exceed an accuracy higher than __90%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve your model by using a LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.rnn.rnn_nn import LSTM_Classifier\n",
    "model= LSTM_Classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your LSTM model again and see wether it improves performance on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your Model\n",
    "When you are satisfied with your training, you can save the model. In order to be eligible for the bonus points you have to achieve a score higher than __97__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model... models/rnn_mnist_nn.model\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "model_rnn.save(\"models/rnn_mnist_nn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
